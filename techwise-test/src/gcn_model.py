# -*- coding: utf-8 -*-
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, GATConv, global_mean_pool
from torch_geometric.data import Data, DataLoader
from typing import Optional, Tuple

class TechBookGCN(nn.Module):
    """
    æŠ€è¡“æ›¸æ¨è–¦ãƒ»åˆ†é¡ç”¨ã®Graph Convolutional Network
    
    ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:
    - Layer1: 1536 â†’ 512 (ç‰¹å¾´æŠ½å‡º)
    - Layer2: 512 â†’ 128 (ä¸­é–“è¡¨ç¾)  
    - Layer3: 128 â†’ 5 (ã‚«ãƒ†ã‚´ãƒªåˆ†é¡)
    - Dropout: 0.2 (éå­¦ç¿’é˜²æ­¢)
    """
    
    def __init__(
        self, 
        input_dim: int = 1536,
        hidden_dim: int = 512,
        intermediate_dim: int = 128,
        output_dim: int = 5,
        dropout: float = 0.2
    ):
        super(TechBookGCN, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.intermediate_dim = intermediate_dim
        self.output_dim = output_dim
        self.dropout = dropout
        
        # GCN Layers
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, intermediate_dim)
        self.conv3 = GCNConv(intermediate_dim, output_dim)
        
        # Batch Normalization
        self.bn1 = nn.BatchNorm1d(hidden_dim)
        self.bn2 = nn.BatchNorm1d(intermediate_dim)
        
        # Dropout
        self.dropout_layer = nn.Dropout(dropout)
        
        print(f"ğŸ§  TechBookGCNåˆæœŸåŒ–å®Œäº†:")
        print(f"  - å…¥åŠ›æ¬¡å…ƒ: {input_dim}")
        print(f"  - éš ã‚Œæ¬¡å…ƒ: {hidden_dim} â†’ {intermediate_dim}")
        print(f"  - å‡ºåŠ›æ¬¡å…ƒ: {output_dim}")
        print(f"  - Dropout: {dropout}")
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        """
        Forward pass
        
        Args:
            x: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ [num_nodes, input_dim]
            edge_index: ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ [2, num_edges]
            
        Returns:
            out: åˆ†é¡çµæœ [num_nodes, output_dim]
        """
        # Layer 1: 1536 â†’ 512
        x = self.conv1(x, edge_index)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.dropout_layer(x)
        
        # Layer 2: 512 â†’ 128
        x = self.conv2(x, edge_index)
        x = self.bn2(x)
        x = F.relu(x)
        x = self.dropout_layer(x)
        
        # Layer 3: 128 â†’ 5 (Classification)
        x = self.conv3(x, edge_index)
        
        return F.log_softmax(x, dim=1)
    
    def get_embeddings(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        """
        æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ä¸­é–“ç‰¹å¾´é‡ã‚’å–å¾—
        
        Args:
            x: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ [num_nodes, input_dim]
            edge_index: ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ [2, num_edges]
            
        Returns:
            embeddings: ä¸­é–“ç‰¹å¾´é‡ [num_nodes, intermediate_dim]
        """
        # Layer 1
        x = self.conv1(x, edge_index)
        x = self.bn1(x)
        x = F.relu(x)
        x = self.dropout_layer(x)
        
        # Layer 2 (æ¨è–¦ç”¨ç‰¹å¾´é‡ã¨ã—ã¦è¿”ã™)
        x = self.conv2(x, edge_index)
        x = self.bn2(x)
        x = F.relu(x)
        
        return x

class TechBookGAT(nn.Module):
    """
    Graph Attention Networkãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    Attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§æ›¸ç±é–“ã®é–¢ä¿‚æ€§ã‚’ã‚ˆã‚Šè©³ç´°ã«å­¦ç¿’
    """
    
    def __init__(
        self, 
        input_dim: int = 1536,
        hidden_dim: int = 512,
        intermediate_dim: int = 128,
        output_dim: int = 5,
        heads: int = 8,
        dropout: float = 0.2
    ):
        super(TechBookGAT, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.intermediate_dim = intermediate_dim
        self.output_dim = output_dim
        self.heads = heads
        self.dropout = dropout
        
        # GAT Layers
        self.conv1 = GATConv(input_dim, hidden_dim // heads, heads=heads, dropout=dropout)
        self.conv2 = GATConv(hidden_dim, intermediate_dim // heads, heads=heads, dropout=dropout)
        self.conv3 = GATConv(intermediate_dim, output_dim, heads=1, dropout=dropout)
        
        # Batch Normalization
        self.bn1 = nn.BatchNorm1d(hidden_dim)
        self.bn2 = nn.BatchNorm1d(intermediate_dim)
        
        print(f"ğŸ§  TechBookGATåˆæœŸåŒ–å®Œäº†:")
        print(f"  - å…¥åŠ›æ¬¡å…ƒ: {input_dim}")
        print(f"  - Attention heads: {heads}")
        print(f"  - éš ã‚Œæ¬¡å…ƒ: {hidden_dim} â†’ {intermediate_dim}")
        print(f"  - å‡ºåŠ›æ¬¡å…ƒ: {output_dim}")
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        """
        Forward pass with attention mechanism
        """
        # Layer 1 with attention
        x = F.relu(self.conv1(x, edge_index))
        x = self.bn1(x)
        x = F.dropout(x, p=self.dropout, training=self.training)
        
        # Layer 2 with attention
        x = F.relu(self.conv2(x, edge_index))
        x = self.bn2(x)
        x = F.dropout(x, p=self.dropout, training=self.training)
        
        # Layer 3 (Classification)
        x = self.conv3(x, edge_index)
        
        return F.log_softmax(x, dim=1)

class LinkPredictor(nn.Module):
    """
    ãƒªãƒ³ã‚¯äºˆæ¸¬ç”¨ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆæ›¸ç±é–“ã®é–¢ä¿‚æ€§äºˆæ¸¬ï¼‰
    """
    
    def __init__(self, embedding_dim: int = 128):
        super(LinkPredictor, self).__init__()
        
        self.embedding_dim = embedding_dim
        
        # ãƒªãƒ³ã‚¯äºˆæ¸¬ç”¨ã®MLP
        self.predictor = nn.Sequential(
            nn.Linear(embedding_dim * 2, embedding_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(embedding_dim, embedding_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(embedding_dim // 2, 1),
            nn.Sigmoid()
        )
        
        print(f"ğŸ”— LinkPredictoråˆæœŸåŒ–å®Œäº† (embedding_dim: {embedding_dim})")
    
    def forward(self, node_embeddings: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        """
        ã‚¨ãƒƒã‚¸ã®å­˜åœ¨ç¢ºç‡ã‚’äºˆæ¸¬
        
        Args:
            node_embeddings: ãƒãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿ [num_nodes, embedding_dim]
            edge_index: ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ [2, num_edges]
            
        Returns:
            predictions: ã‚¨ãƒƒã‚¸å­˜åœ¨ç¢ºç‡ [num_edges]
        """
        # ã‚¨ãƒƒã‚¸ã®ä¸¡ç«¯ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´é‡ã‚’å–å¾—
        source_embeddings = node_embeddings[edge_index[0]]
        target_embeddings = node_embeddings[edge_index[1]]
        
        # é€£çµã—ãŸç‰¹å¾´é‡ã§ãƒªãƒ³ã‚¯äºˆæ¸¬
        edge_embeddings = torch.cat([source_embeddings, target_embeddings], dim=1)
        predictions = self.predictor(edge_embeddings).squeeze()
        
        return predictions

def create_pytorch_geometric_data(
    node_features: torch.Tensor, 
    edge_index: torch.Tensor, 
    labels: torch.Tensor
) -> Data:
    """
    PyTorch Geometricã®Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    
    Args:
        node_features: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ [num_nodes, feature_dim]
        edge_index: ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ [2, num_edges]
        labels: ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ« [num_nodes]
        
    Returns:
        data: PyTorch Geometricã®Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    data = Data(
        x=node_features,
        edge_index=edge_index,
        y=labels
    )
    
    print(f"ğŸ“Š PyTorch Geometric Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆå®Œäº†:")
    print(f"  - ãƒãƒ¼ãƒ‰æ•°: {data.num_nodes}")
    print(f"  - ã‚¨ãƒƒã‚¸æ•°: {data.num_edges}")
    print(f"  - ç‰¹å¾´é‡æ¬¡å…ƒ: {data.num_node_features}")
    print(f"  - ã‚¯ãƒ©ã‚¹æ•°: {len(torch.unique(labels))}")
    
    return data

if __name__ == "__main__":
    # ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ
    print("ğŸ”¬ GCNãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ:")
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
    num_nodes = 50
    input_dim = 1536
    num_edges = 100
    
    x = torch.randn(num_nodes, input_dim)
    edge_index = torch.randint(0, num_nodes, (2, num_edges))
    labels = torch.randint(0, 5, (num_nodes,))
    
    # GCNãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
    model = TechBookGCN(input_dim=input_dim)
    output = model(x, edge_index)
    embeddings = model.get_embeddings(x, edge_index)
    
    print(f"âœ… GCNå‡ºåŠ›å½¢çŠ¶: {output.shape}")
    print(f"âœ… åŸ‹ã‚è¾¼ã¿å½¢çŠ¶: {embeddings.shape}")
    
    # GATãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
    gat_model = TechBookGAT(input_dim=input_dim)
    gat_output = gat_model(x, edge_index)
    
    print(f"âœ… GATå‡ºåŠ›å½¢çŠ¶: {gat_output.shape}")
    
    # ãƒªãƒ³ã‚¯äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
    link_predictor = LinkPredictor(embedding_dim=128)
    link_predictions = link_predictor(embeddings, edge_index)
    
    print(f"âœ… ãƒªãƒ³ã‚¯äºˆæ¸¬å½¢çŠ¶: {link_predictions.shape}")
    
    print("ğŸ‰ ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
