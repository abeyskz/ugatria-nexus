#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TechWise GCN ç°¡æ˜“ãƒ‡ãƒ¢ (PyTorchä¸è¦ãƒãƒ¼ã‚¸ãƒ§ãƒ³)
ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨åŸºæœ¬çš„ãªåˆ†ææ©Ÿèƒ½ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import psycopg2
from psycopg2.extras import RealDictCursor
import numpy as np
import json
from typing import List, Dict, Any, Tuple
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns

# DBè¨­å®š
DB_CONFIG = {
    "host": "localhost",
    "database": "techwise_db",
    "user": "abeys",
    "password": ""
}

class SimpleTechBookAnalyzer:
    """
    PyTorchä¸è¦ã®ã‚·ãƒ³ãƒ—ãƒ«ãªæŠ€è¡“æ›¸åˆ†æã‚·ã‚¹ãƒ†ãƒ 
    """
    
    def __init__(self):
        self.books = []
        self.embeddings = []
        self.category_mapping = {
            'AI': 0, 'æ©Ÿæ¢°å­¦ç¿’': 0, 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹': 0,
            'Python': 1, 'ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰': 1, 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': 1,
            'ã‚¯ãƒ©ã‚¦ãƒ‰': 2, 'ã‚¤ãƒ³ãƒ•ãƒ©': 2, 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': 2,
            'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰': 3, 'Webé–‹ç™º': 3,
            'ãã®ä»–': 4
        }
        self.category_names = ['AI/ML', 'Python/Backend', 'Infrastructure', 'Frontend', 'Other']
        
        print("ğŸš€ SimpleTechBookAnalyzeråˆæœŸåŒ–å®Œäº†")
    
    def parse_embedding_vector(self, embedding_data) -> List[float]:
        """PostgreSQL VECTORå‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ"""
        try:
            if embedding_data is None:
                return []
            
            if isinstance(embedding_data, str):
                embedding_data = embedding_data.strip('[]')
                return [float(x.strip()) for x in embedding_data.split(',')]
            elif isinstance(embedding_data, list):
                if len(embedding_data) > 0 and isinstance(embedding_data[0], str):
                    vector_str = ''.join(embedding_data)
                    vector_str = vector_str.strip('[]')
                    return [float(x.strip()) for x in vector_str.split(',')]
                else:
                    return [float(x) for x in embedding_data]
            elif hasattr(embedding_data, 'tolist'):
                return embedding_data.tolist()
            else:
                return []
        except Exception as e:
            print(f"âŒ Embeddingãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _get_primary_category(self, tech_categories: List[str]) -> str:
        """æŠ€è¡“ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ä¸»è¦ã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®š"""
        if not tech_categories:
            return "ãã®ä»–"
        
        for category in tech_categories:
            if any(keyword in category for keyword in ['AI', 'æ©Ÿæ¢°å­¦ç¿’', 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹']):
                return 'AI'
            elif any(keyword in category for keyword in ['Python', 'ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°']):
                return 'Python'
            elif any(keyword in category for keyword in ['ã‚¯ãƒ©ã‚¦ãƒ‰', 'ã‚¤ãƒ³ãƒ•ãƒ©', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£']):
                return 'ã‚¤ãƒ³ãƒ•ãƒ©'
            elif any(keyword in category for keyword in ['ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰', 'Web']):
                return 'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰'
        
        return 'ãã®ä»–'
    
    def load_books_from_db(self) -> List[Dict[str, Any]]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ›¸ç±ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        print("ğŸ“š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ›¸ç±ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        try:
            with psycopg2.connect(**DB_CONFIG) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    query = """
                        SELECT isbn, title, subtitle, authors, publisher, published_date,
                               page_count, description, difficulty_level, tech_categories,
                               target_audience, analysis_summary, embedding
                        FROM books
                        WHERE embedding IS NOT NULL
                        ORDER BY title
                    """
                    cursor.execute(query)
                    rows = cursor.fetchall()
                    
                    books = []
                    embeddings = []
                    
                    for row in rows:
                        embedding = self.parse_embedding_vector(row["embedding"])
                        if len(embedding) == 1536:  # æœ‰åŠ¹ãªembeddingã®ã¿
                            book_data = {
                                "id": row["isbn"],
                                "title": row["title"],
                                "subtitle": row["subtitle"] or "",
                                "authors": row["authors"] or [],
                                "publisher": row["publisher"] or "",
                                "published_date": str(row["published_date"]) if row["published_date"] else "",
                                "page_count": row["page_count"] or 0,
                                "description": row["description"] or "",
                                "difficulty_level": row["difficulty_level"] or 1,
                                "tech_categories": row["tech_categories"] or [],
                                "target_audience": row["target_audience"] or "",
                                "analysis_summary": row["analysis_summary"] or "",
                                "primary_category": self._get_primary_category(row["tech_categories"] or [])
                            }
                            books.append(book_data)
                            embeddings.append(embedding)
                    
                    self.books = books
                    self.embeddings = np.array(embeddings)
                    
                    print(f"âœ… {len(books)} å†Šã®æ›¸ç±ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
                    print(f"  - åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«å½¢çŠ¶: {self.embeddings.shape}")
                    
                    return books
                    
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def analyze_data_distribution(self):
        """ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã‚’åˆ†æ"""
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒåˆ†æ")
        print("=" * 50)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
        category_counts = {}
        difficulty_counts = {}
        
        for book in self.books:
            cat = book['primary_category']
            category_counts[cat] = category_counts.get(cat, 0) + 1
            
            diff = book['difficulty_level']
            difficulty_counts[diff] = difficulty_counts.get(diff, 0) + 1
        
        print("ğŸ“š ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:")
        for category, count in sorted(category_counts.items()):
            percentage = (count / len(self.books)) * 100
            print(f"  - {category}: {count}å†Š ({percentage:.1f}%)")
        
        print("\nğŸ¯ é›£æ˜“åº¦åˆ†å¸ƒ:")
        for level in sorted(difficulty_counts.keys()):
            count = difficulty_counts[level]
            percentage = (count / len(self.books)) * 100
            print(f"  - ãƒ¬ãƒ™ãƒ«{level}: {count}å†Š ({percentage:.1f}%)")
        
        return category_counts, difficulty_counts
    
    def build_similarity_graph(self, threshold: float = 0.6) -> Tuple[np.ndarray, int]:
        """é¡ä¼¼åº¦ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
        print(f"\nğŸ”— é¡ä¼¼åº¦ã‚°ãƒ©ãƒ•æ§‹ç¯‰ (ã—ãã„å€¤: {threshold})")
        print("=" * 50)
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
        similarity_matrix = cosine_similarity(self.embeddings)
        
        # ã‚¨ãƒƒã‚¸æ•°è¨ˆç®—
        edges = 0
        edge_list = []
        
        for i in range(len(self.books)):
            for j in range(i + 1, len(self.books)):
                if similarity_matrix[i][j] >= threshold:
                    edges += 2  # ç„¡å‘ã‚°ãƒ©ãƒ•ãªã®ã§åŒæ–¹å‘
                    edge_list.append((i, j, similarity_matrix[i][j]))
        
        print(f"ğŸ“ˆ ã‚°ãƒ©ãƒ•çµ±è¨ˆ:")
        print(f"  - ãƒãƒ¼ãƒ‰æ•°: {len(self.books)}")
        print(f"  - ã‚¨ãƒƒã‚¸æ•°: {edges}")
        print(f"  - å¯†åº¦: {edges / (len(self.books) * (len(self.books) - 1)):.6f}")
        print(f"  - æ¥ç¶šãƒšã‚¢æ•°: {len(edge_list)}")
        
        return similarity_matrix, len(edge_list)
    
    def find_similar_books(self, book_index: int, n_recommendations: int = 5) -> List[Dict]:
        """é¡ä¼¼æ›¸ç±ã‚’æ¤œç´¢"""
        if len(self.embeddings) == 0:
            return []
        
        target_embedding = self.embeddings[book_index].reshape(1, -1)
        similarities = cosine_similarity(target_embedding, self.embeddings)[0]
        
        # è‡ªåˆ†è‡ªèº«ã‚’é™¤å¤–
        similarities[book_index] = -1
        
        # é¡ä¼¼åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        similar_indices = np.argsort(similarities)[::-1]
        
        recommendations = []
        for i, idx in enumerate(similar_indices[:n_recommendations]):
            if similarities[idx] < 0.3:  # æœ€ä½é¡ä¼¼åº¦
                break
            
            rec = {
                'rank': i + 1,
                'book_index': int(idx),
                'title': self.books[idx]['title'],
                'authors': self.books[idx]['authors'],
                'publisher': self.books[idx]['publisher'],
                'similarity_score': float(similarities[idx]),
                'category': self.books[idx]['primary_category'],
                'difficulty_level': self.books[idx]['difficulty_level']
            }
            recommendations.append(rec)
        
        return recommendations
    
    def recommend_by_keywords(self, keywords: List[str], n_recommendations: int = 5) -> List[Dict]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹æ¨è–¦"""
        book_scores = []
        
        for i, book in enumerate(self.books):
            score = 0.0
            
            # ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒƒãƒãƒ³ã‚°
            title_words = book['title'].lower().split()
            for keyword in keywords:
                if any(keyword.lower() in word for word in title_words):
                    score += 2.0
            
            # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒãƒ³ã‚°
            for category in book['tech_categories']:
                for keyword in keywords:
                    if keyword.lower() in category.lower():
                        score += 1.5
            
            # èª¬æ˜æ–‡ãƒãƒƒãƒãƒ³ã‚°
            if book['description']:
                description = book['description'].lower()
                for keyword in keywords:
                    if keyword.lower() in description:
                        score += 1.0
            
            book_scores.append((i, score))
        
        # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
        book_scores.sort(key=lambda x: x[1], reverse=True)
        
        recommendations = []
        for rank, (book_index, score) in enumerate(book_scores[:n_recommendations]):
            if score == 0:
                break
            
            rec = {
                'rank': rank + 1,
                'book_index': book_index,
                'title': self.books[book_index]['title'],
                'authors': self.books[book_index]['authors'],
                'match_score': score,
                'category': self.books[book_index]['primary_category'],
                'difficulty_level': self.books[book_index]['difficulty_level']
            }
            recommendations.append(rec)
        
        return recommendations
    
    def print_recommendations(self, recommendations: List[Dict], title: str = "æ¨è–¦çµæœ"):
        """æ¨è–¦çµæœã‚’è¡¨ç¤º"""
        print(f"\nğŸ“š {title} ({len(recommendations)}å†Š):")
        print("=" * 80)
        
        for rec in recommendations:
            print(f"\n{rec['rank']}. {rec['title']}")
            authors = ', '.join(rec['authors']) if rec['authors'] else 'ä¸æ˜'
            print(f"   è‘—è€…: {authors}")
            print(f"   ã‚«ãƒ†ã‚´ãƒª: {rec['category']}")
            print(f"   é›£æ˜“åº¦: {rec['difficulty_level']}")
            
            if 'similarity_score' in rec:
                print(f"   é¡ä¼¼åº¦: {rec['similarity_score']:.3f}")
            if 'match_score' in rec:
                print(f"   ãƒãƒƒãƒã‚¹ã‚³ã‚¢: {rec['match_score']:.1f}")
        
        print("\n" + "=" * 80)
    
    def demo_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ"""
        print("ğŸ¬ TechWise ç°¡æ˜“GCNã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢")
        print("=" * 80)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if len(self.books) == 0:
            self.load_books_from_db()
        
        if len(self.books) == 0:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†æ
        self.analyze_data_distribution()
        
        # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
        similarity_matrix, edge_count = self.build_similarity_graph(threshold=0.6)
        
        # 1. é¡ä¼¼æ›¸ç±æ¨è–¦ãƒ‡ãƒ¢
        print("\nğŸ” 1. é¡ä¼¼æ›¸ç±æ¨è–¦ãƒ‡ãƒ¢")
        target_index = 0
        target_book = self.books[target_index]
        print(f"åŸºæº–æ›¸ç±: {target_book['title']}")
        print(f"ã‚«ãƒ†ã‚´ãƒª: {', '.join(target_book['tech_categories'])}")
        
        similar_books = self.find_similar_books(target_index, n_recommendations=3)
        self.print_recommendations(similar_books, "é¡ä¼¼æ›¸ç±")
        
        # 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ãƒ‡ãƒ¢
        print("\nğŸ” 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ãƒ‡ãƒ¢")
        keywords = ["Python", "æ©Ÿæ¢°å­¦ç¿’", "AI"]
        print(f"æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords}")
        
        keyword_results = self.recommend_by_keywords(keywords, n_recommendations=3)
        self.print_recommendations(keyword_results, "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœ")
        
        # 3. ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
        print("\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ:")
        print(f"  - ç·æ›¸ç±æ•°: {len(self.books)}")
        print(f"  - åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: {self.embeddings.shape[1]}")
        print(f"  - ã‚°ãƒ©ãƒ•ã‚¨ãƒƒã‚¸æ•°: {edge_count}")
        print(f"  - å¹³å‡é¡ä¼¼åº¦: {np.mean(similarity_matrix):.4f}")
        
        print("\nğŸ‰ ãƒ‡ãƒ¢å®Œäº†ï¼")
        print("ğŸ’¡ PyTorchã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€ãƒ•ãƒ«GCNã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    analyzer = SimpleTechBookAnalyzer()
    analyzer.demo_system()

if __name__ == "__main__":
    main()
