# -*- coding: utf-8 -*-
import json
import numpy as np
import pandas as pd
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import List, Dict, Any, Tuple
import torch
from sklearn.preprocessing import LabelEncoder

# DBè¨­å®šï¼ˆtechwise_2stage_fixed_db.pyã‹ã‚‰å–å¾—ï¼‰
DB_CONFIG = {
    "host": "localhost",
    "database": "techwise_db",
    "user": "abeys",
    "password": ""
}

class TechBookDataLoader:
    """
    æŠ€è¡“æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLã‹ã‚‰å–å¾—ã—ã€GCNç”¨ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã«å¤‰æ›ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self):
        self.books = []
        self.category_encoder = LabelEncoder()
        self.category_mapping = {
            'AI': 0, 'æ©Ÿæ¢°å­¦ç¿’': 0, 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹': 0,
            'Python': 1, 'ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰': 1, 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': 1,
            'ã‚¯ãƒ©ã‚¦ãƒ‰': 2, 'ã‚¤ãƒ³ãƒ•ãƒ©': 2, 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': 2,
            'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰': 3, 'Webé–‹ç™º': 3,
            'ãã®ä»–': 4
        }
    
    def parse_embedding_vector(self, embedding_data) -> List[float]:
        """
        PostgreSQL VECTORå‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’floatã®ãƒªã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ã€‚
        """
        try:
            if embedding_data is None:
                return []
            
            # VECTORå‹ã¯æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹
            if isinstance(embedding_data, str):
                # '[0.1, 0.2, 0.3]' å½¢å¼ã®æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
                embedding_data = embedding_data.strip('[]')
                return [float(x.strip()) for x in embedding_data.split(',')]
            
            # æ—¢ã«ãƒªã‚¹ãƒˆã®å ´åˆ
            elif isinstance(embedding_data, list):
                # æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã®å ´åˆã€çµåˆã—ã¦ãƒ‘ãƒ¼ã‚¹
                if len(embedding_data) > 0 and isinstance(embedding_data[0], str):
                    vector_str = ''.join(embedding_data)
                    vector_str = vector_str.strip('[]')
                    return [float(x.strip()) for x in vector_str.split(',')]
                else:
                    return [float(x) for x in embedding_data]
            
            # numpy arrayã®å ´åˆ
            elif hasattr(embedding_data, 'tolist'):
                return embedding_data.tolist()
            
            else:
                print(f"âš ï¸ ä¸æ˜ãªembeddingãƒ‡ãƒ¼ã‚¿å½¢å¼: {type(embedding_data)}")
                return []
        
        except Exception as e:
            print(f"âŒ Embeddingãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def load_books_from_db(self) -> List[Dict[str, Any]]:
        """
        PostgreSQLã®techwise_dbã‹ã‚‰æ›¸ç±ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã€‚
        """
        try:
            with psycopg2.connect(**DB_CONFIG) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    query = """
                        SELECT isbn, title, subtitle, authors, publisher, published_date,
                               page_count, description, difficulty_level, tech_categories,
                               target_audience, analysis_summary, embedding
                        FROM books
                        WHERE embedding IS NOT NULL
                        ORDER BY title
                    """
                    cursor.execute(query)
                    rows = cursor.fetchall()
                    
                    books = []
                    for row in rows:
                        book_data = {
                            "id": row["isbn"],
                            "title": row["title"],
                            "subtitle": row["subtitle"] or "",
                            "authors": row["authors"] or [],
                            "publisher": row["publisher"] or "",
                            "published_date": str(row["published_date"]) if row["published_date"] else "",
                            "page_count": row["page_count"] or 0,
                            "description": row["description"] or "",
                            "difficulty_level": row["difficulty_level"] or 1,
                            "tech_categories": row["tech_categories"] or [],
                            "target_audience": row["target_audience"] or "",
                            "analysis_summary": row["analysis_summary"] or "",
                            "embedding": self.parse_embedding_vector(row["embedding"]),
                            "primary_category": self._get_primary_category(row["tech_categories"] or [])
                        }
                        books.append(book_data)
                    
                    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ {len(books)} å†Šã®æ›¸ç±ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
                    return books
                    
        except psycopg2.Error as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return []
        except Exception as e:
            print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _get_primary_category(self, tech_categories: List[str]) -> str:
        """
        æŠ€è¡“ã‚«ãƒ†ã‚´ãƒªã®ãƒªã‚¹ãƒˆã‹ã‚‰ä¸»è¦ã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®šã™ã‚‹
        """
        if not tech_categories:
            return "ãã®ä»–"
        
        # å„ªå…ˆé †ä½ã§ã‚«ãƒ†ã‚´ãƒªã‚’æ±ºå®š
        for category in tech_categories:
            if any(keyword in category for keyword in ['AI', 'æ©Ÿæ¢°å­¦ç¿’', 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹']):
                return 'AI'
            elif any(keyword in category for keyword in ['Python', 'ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°']):
                return 'Python'
            elif any(keyword in category for keyword in ['ã‚¯ãƒ©ã‚¦ãƒ‰', 'ã‚¤ãƒ³ãƒ•ãƒ©', 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£']):
                return 'ã‚¤ãƒ³ãƒ•ãƒ©'
            elif any(keyword in category for keyword in ['ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰', 'Web']):
                return 'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰'
        
        return 'ãã®ä»–'
    
    def create_category_labels(self, books: List[Dict]) -> torch.Tensor:
        """
        æ›¸ç±ã®ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ãƒ©ãƒ™ãƒ«ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
        """
        categories = [book["primary_category"] for book in books]
        labels = [self.category_mapping.get(cat, 4) for cat in categories]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯4ï¼ˆãã®ä»–ï¼‰
        return torch.tensor(labels, dtype=torch.long)
    
    def create_edge_index(self, books: List[Dict], similarity_threshold: float = 0.6) -> torch.Tensor:
        """
        æ›¸ç±é–“ã®é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        """
        from sklearn.metrics.pairwise import cosine_similarity
        
        embeddings = [book["embedding"] for book in books if book["embedding"]]
        if len(embeddings) == 0:
            return torch.empty((2, 0), dtype=torch.long)
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
        similarity_matrix = cosine_similarity(embeddings)
        
        # ã—ãã„å€¤ä»¥ä¸Šã®é¡ä¼¼åº¦ã‚’æŒã¤ãƒšã‚¢ã‚’æŠ½å‡º
        edge_list = []
        n_books = len(books)
        
        for i in range(n_books):
            for j in range(i + 1, n_books):
                if similarity_matrix[i][j] >= similarity_threshold:
                    edge_list.append([i, j])
                    edge_list.append([j, i])  # ç„¡å‘ã‚°ãƒ©ãƒ•ãªã®ã§åŒæ–¹å‘
        
        if len(edge_list) == 0:
            return torch.empty((2, 0), dtype=torch.long)
        
        edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()
        return edge_index
    
    def create_node_features(self, books: List[Dict]) -> torch.Tensor:
        """
        æ›¸ç±ã®embeddingã‹ã‚‰ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
        """
        embeddings = []
        for book in books:
            if book["embedding"] and len(book["embedding"]) == 1536:
                embeddings.append(book["embedding"])
            else:
                # embeddingãŒç„¡ã„å ´åˆã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«
                embeddings.append([0.0] * 1536)
        
        return torch.tensor(embeddings, dtype=torch.float)
    
    def load_graph_data(self, similarity_threshold: float = 0.6) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[Dict]]:
        """
        GCNç”¨ã®ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        
        Returns:
            node_features: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ [num_nodes, 1536]
            edge_index: ã‚¨ãƒƒã‚¸ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ [2, num_edges]
            labels: ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ« [num_nodes]
            books: æ›¸ç±ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        print("ğŸ“š æŠ€è¡“æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        books = self.load_books_from_db()
        
        if not books:
            raise ValueError("æ›¸ç±ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        
        print("ğŸ”— ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ä¸­...")
        node_features = self.create_node_features(books)
        edge_index = self.create_edge_index(books, similarity_threshold)
        labels = self.create_category_labels(books)
        
        print(f"ğŸ“Š ã‚°ãƒ©ãƒ•çµ±è¨ˆ:")
        print(f"  - ãƒãƒ¼ãƒ‰æ•°: {len(books)}")
        print(f"  - ã‚¨ãƒƒã‚¸æ•°: {edge_index.size(1)}")
        print(f"  - ç‰¹å¾´é‡æ¬¡å…ƒ: {node_features.size(1)}")
        print(f"  - ã‚«ãƒ†ã‚´ãƒªæ•°: {len(set(labels.tolist()))}")
        
        return node_features, edge_index, labels, books

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    loader = TechBookDataLoader()
    node_features, edge_index, labels, books = loader.load_graph_data()
    
    print("\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:")
    print(f"æœ€åˆã®æ›¸ç±: {books[0]['title']}")
    print(f"ã‚«ãƒ†ã‚´ãƒª: {books[0]['primary_category']}")
    print(f"ãƒ©ãƒ™ãƒ«: {labels[0].item()}")
