//
//  AudioRecorder.swift
//  PocoriConversation
//
//  èª¤æ¤œå‡ºè»½æ¸›ï¼‹AudioSessionä¿®æ­£ç‰ˆ
//

import SwiftUI
import AVFoundation

// MARK: - VADæ©Ÿèƒ½ä»˜ãAudioRecorder ã‚¯ãƒ©ã‚¹
class AudioRecorder: ObservableObject {
    @Published var isListening = false      // å¸¸æ™‚ç›£è¦–çŠ¶æ…‹
    @Published var isRecording = false      // å®Ÿéš›ã®éŒ²éŸ³çŠ¶æ…‹
    @Published var isThinking = false      // å®Ÿéš›ã®æ€è€ƒä¸­çŠ¶æ…‹
    @Published var transcriptionResult = ""
    @Published var statusMessage = ""
    
    private var whisperStartTime: Date?
    
    // ğŸ”§ VADè¨­å®šï¼ˆèª¤æ¤œå‡ºè»½æ¸›ï¼‰
    private var volumeThreshold: Float = -17.0        // -20.0 â†’ -17.0 (èª¤æ¤œå‡ºè»½æ¸›)
    private var silenceDuration: TimeInterval = 2.0   // ç„¡éŸ³æ¤œå‡ºæ™‚é–“ï¼ˆç§’ï¼‰
    private var monitoringInterval: TimeInterval = 0.08 // 0.05 â†’ 0.08 (é©åº¦ãªç›£è¦–é–“éš”)
    
    // ã‚¿ã‚¤ãƒãƒ¼ã¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    private var silenceTimer: Timer?
    private var monitoringTimer: Timer?
    private var lastSoundTime: Date?
    
    // éŒ²éŸ³é–¢é€£
    private var audioRecorder: AVAudioRecorder?        // å®Ÿéš›ã®éŒ²éŸ³ç”¨
    private var monitoringRecorder: AVAudioRecorder?   // ç›£è¦–ç”¨
    private var audioSession = AVAudioSession.sharedInstance()
    
    // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã®URL
    private var recordingURL: URL {
        let documentsPath = FileManager.default.urls(for: .documentDirectory,
                                                   in: .userDomainMask)[0]
        return documentsPath.appendingPathComponent("recording.m4a")
    }
    
    // ç›£è¦–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã®URLï¼ˆå®Ÿéš›ã¯ä½¿ã‚ãªã„ãŒå¿…è¦ï¼‰
    private var monitoringURL: URL {
        let documentsPath = FileManager.default.urls(for: .documentDirectory,
                                                   in: .userDomainMask)[0]
        return documentsPath.appendingPathComponent("monitoring.m4a")
    }
    
    // MARK: - æ¨©é™è¦æ±‚
    func requestPermission() {
        audioSession.requestRecordPermission { granted in
            DispatchQueue.main.async {
                if granted {
                    self.statusMessage = "ãƒã‚¤ã‚¯æ¨©é™ãŒè¨±å¯ã•ã‚Œã¾ã—ãŸ"
                } else {
                    self.statusMessage = "ãƒã‚¤ã‚¯æ¨©é™ãŒå¿…è¦ã§ã™"
                }
            }
        }
    }
    
    // MARK: - å¸¸æ™‚éŸ³å£°ç›£è¦–é–‹å§‹
    func startListening() {
        do {
            // ğŸ”§ AudioSessionè¨­å®šæ”¹è‰¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³å‰Šé™¤ï¼‰
            try audioSession.setCategory(.record, mode: .default)
            try audioSession.setActive(true)
            
            // ç›£è¦–ç”¨éŒ²éŸ³è¨­å®šï¼ˆè»½é‡è¨­å®šï¼‰
            let monitoringSettings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
                AVSampleRateKey: 16000,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.low.rawValue  // è»½é‡è¨­å®š
            ]
            
            // ç›£è¦–ç”¨éŒ²éŸ³é–‹å§‹
            monitoringRecorder = try AVAudioRecorder(url: monitoringURL, settings: monitoringSettings)
            monitoringRecorder?.isMeteringEnabled = true  // éŸ³é‡æ¸¬å®šæœ‰åŠ¹
            monitoringRecorder?.record()
            
            isListening = true
            statusMessage = "éŸ³å£°ç›£è¦–ä¸­..."
            print("ğŸ™ï¸ VADç›£è¦–é–‹å§‹ï¼ˆãƒãƒ©ãƒ³ã‚¹è¨­å®šï¼š-17.0dBï¼‰")
            
            // éŸ³é‡ç›£è¦–ãƒ«ãƒ¼ãƒ—é–‹å§‹
            startMonitoringLoop()
            
        } catch {
            statusMessage = "ç›£è¦–é–‹å§‹ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
            print("âŒ VADç›£è¦–é–‹å§‹ã‚¨ãƒ©ãƒ¼: \(error)")
        }
    }
    
    // MARK: - å¸¸æ™‚éŸ³å£°ç›£è¦–åœæ­¢ï¼ˆAudioSessionä¿®æ­£ç‰ˆï¼‰
    func stopListening() {
        monitoringTimer?.invalidate()
        silenceTimer?.invalidate()
        monitoringRecorder?.stop()
        
        // ğŸ”§ AVAudioRecorderã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å®Œå…¨ç ´æ£„
        monitoringRecorder = nil
        audioRecorder?.stop()
        audioRecorder = nil
        
        isListening = false
        isRecording = false
        statusMessage = "ç›£è¦–åœæ­¢"
        print("ğŸ™ï¸ VADç›£è¦–åœæ­¢")
        
        // ğŸš€ AudioSessionå•é¡Œä¿®æ­£ï¼ˆç¢ºå®Ÿãªåˆ‡ã‚Šæ›¿ãˆï¼‰
        do {
            // Step 1: ä¸€æ—¦éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ã™ã‚‹
            try audioSession.setActive(false)
            print("ğŸ”Š AudioSessionä¸€æ™‚éã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–å®Œäº†")
            
            // Step 2: ã‚«ãƒ†ã‚´ãƒªã‚’.playbackã«åˆ‡ã‚Šæ›¿ãˆ
            try audioSession.setCategory(.playback, mode: .default)
            
            // Step 3: å†ã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–
            try audioSession.setActive(true)
            print("ğŸ”Š AudioSessionã‚’.playbackã«åˆ‡ã‚Šæ›¿ãˆå®Œäº†ï¼ˆä¿®æ­£ç‰ˆï¼‰")
            
        } catch {
            print("âŒ AudioSessionåˆ‡ã‚Šæ›¿ãˆå¤±æ•—: \(error)")
            
            // ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
                do {
                    try self.audioSession.setCategory(.playback, mode: .default)
                    try self.audioSession.setActive(true)
                    print("ğŸ”Š AudioSessionãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ")
                } catch {
                    print("âŒ AudioSessionãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—: \(error)")
                }
            }
        }
    }
    
    // MARK: - éŸ³é‡ç›£è¦–ãƒ«ãƒ¼ãƒ—
    private func startMonitoringLoop() {
        monitoringTimer = Timer.scheduledTimer(withTimeInterval: monitoringInterval, repeats: true) { [weak self] _ in
            self?.monitorAudioLevel()
        }
    }
    
    // MARK: - éŸ³é‡ãƒ¬ãƒ™ãƒ«ç›£è¦–ï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆï¼‰
    private func monitorAudioLevel() {
        guard let recorder = monitoringRecorder, isListening, !isThinking else { return }
        
        recorder.updateMeters()
        let currentVolume = recorder.averagePower(forChannel: 0)
        
        // ğŸ”§ éŸ³å£°æ¤œå‡ºæ™‚ã®ã¿ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆãƒã‚¤ã‚ºè»½æ¸›ï¼‰
        if currentVolume > volumeThreshold {
            print("ğŸ”Š éŸ³å£°æ¤œå‡º: \(String(format: "%.1f", currentVolume))dB (é–¾å€¤: \(volumeThreshold)dB)")
        }
        
        if currentVolume > volumeThreshold {
            // éŸ³å£°æ¤œå‡º
            lastSoundTime = Date()
            
            if !isRecording {
                // éŒ²éŸ³é–‹å§‹
                autoStartRecording()
            }
            
            // ç„¡éŸ³ã‚¿ã‚¤ãƒãƒ¼ãƒªã‚»ãƒƒãƒˆ
            silenceTimer?.invalidate()
            silenceTimer = nil
            
        } else if isRecording {
            // ç„¡éŸ³çŠ¶æ…‹ã§éŒ²éŸ³ä¸­ã®å ´åˆ
            if silenceTimer == nil {
                // ç„¡éŸ³ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
                print("â° ç„¡éŸ³ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹")
                startSilenceTimer()
            }
        }
    }
    
    // MARK: - ç„¡éŸ³ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
    private func startSilenceTimer() {
        silenceTimer = Timer.scheduledTimer(withTimeInterval: silenceDuration, repeats: false) { [weak self] _ in
            print("â° ç„¡éŸ³ã‚¿ã‚¤ãƒãƒ¼ç™ºç« â†’ éŒ²éŸ³çµ‚äº†")
            self?.autoStopRecording()
        }
    }
    
    // MARK: - è‡ªå‹•éŒ²éŸ³é–‹å§‹
    private func autoStartRecording() {
        guard !isRecording else { return }
        
        do {
            // å®Ÿéš›ã®éŒ²éŸ³è¨­å®šï¼ˆé«˜å“è³ªï¼‰
            let recordingSettings: [String: Any] = [
                AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
                AVSampleRateKey: 16000,  // Whisper APIæ¨å¥¨
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]
            
            // éŒ²éŸ³é–‹å§‹
            audioRecorder = try AVAudioRecorder(url: recordingURL, settings: recordingSettings)
            audioRecorder?.record()
            
            isRecording = true
            statusMessage = "éŒ²éŸ³ä¸­..."
            print("ğŸ™ï¸ è‡ªå‹•éŒ²éŸ³é–‹å§‹ï¼ˆãƒãƒ©ãƒ³ã‚¹è¨­å®šï¼‰")
            
        } catch {
            statusMessage = "éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
            print("âŒ è‡ªå‹•éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: \(error)")
        }
    }
    
    // MARK: - è‡ªå‹•éŒ²éŸ³çµ‚äº†
    private func autoStopRecording() {
        guard isRecording else { return }
        
        audioRecorder?.stop()
        silenceTimer?.invalidate()
        
        isRecording = false
        statusMessage = "éŸ³å£°å‡¦ç†ä¸­..."
        print("ğŸ™ï¸ è‡ªå‹•éŒ²éŸ³çµ‚äº†")
        
        // éŒ²éŸ³åœæ­¢å¾Œã€Whisper APIã«é€ä¿¡
        sendToWhisperAPI()
    }
    
    // MARK: - Whisper APIé€ä¿¡
    private func sendToWhisperAPI() {
        guard FileManager.default.fileExists(atPath: recordingURL.path) else {
            statusMessage = "éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            return
        }
        
        // éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        let fileSize = try? recordingURL.resourceValues(forKeys: [.fileSizeKey]).fileSize
        if let size = fileSize, size < 1000 {  // 1KBæœªæº€ã¯ç„¡éŸ³ã¨ã¿ãªã™
            statusMessage = "éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
            return
        }
        
        // å‡¦ç†æ™‚é–“æ¸¬å®šé–‹å§‹
        whisperStartTime = Date()
        statusMessage = "Whisper APIã«é€ä¿¡ä¸­..."
        print("ğŸ™ï¸ Whisper APIå‡¦ç†é–‹å§‹: \(Date())")
        
        // OpenAI APIè¨­å®š
        let apiKey = "[OPENAI_API_KEY_PLACEHOLDER]"
        let url = URL(string: "https://api.openai.com/v1/audio/transcriptions")!
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        
        // ãƒãƒ«ãƒãƒ‘ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        let boundary = UUID().uuidString
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")
        
        var data = Data()
        
        // model ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        data.append("--\(boundary)\r\n".data(using: .utf8)!)
        data.append("Content-Disposition: form-data; name=\"model\"\r\n\r\n".data(using: .utf8)!)
        data.append("whisper-1\r\n".data(using: .utf8)!)
        
        // language ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ—¥æœ¬èªæŒ‡å®šï¼‰
        data.append("--\(boundary)\r\n".data(using: .utf8)!)
        data.append("Content-Disposition: form-data; name=\"language\"\r\n\r\n".data(using: .utf8)!)
        data.append("ja\r\n".data(using: .utf8)!)
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿
        do {
            let audioData = try Data(contentsOf: recordingURL)
            data.append("--\(boundary)\r\n".data(using: .utf8)!)
            data.append("Content-Disposition: form-data; name=\"file\"; filename=\"recording.m4a\"\r\n".data(using: .utf8)!)
            data.append("Content-Type: audio/mp4\r\n\r\n".data(using: .utf8)!)
            data.append(audioData)
            data.append("\r\n".data(using: .utf8)!)
        } catch {
            DispatchQueue.main.async {
                self.statusMessage = "ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
            }
            return
        }
        
        // çµ‚ç«¯
        data.append("--\(boundary)--\r\n".data(using: .utf8)!)
        
        request.httpBody = data
        
        // APIé€ä¿¡
        URLSession.shared.dataTask(with: request) { [weak self] responseData, response, error in
            DispatchQueue.main.async {
                guard let self = self else { return }
                
                if let error = error {
                    self.statusMessage = "APIé€šä¿¡ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
                    return
                }
                
                guard let httpResponse = response as? HTTPURLResponse else {
                    self.statusMessage = "ç„¡åŠ¹ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹"
                    return
                }
                
                guard let data = responseData else {
                    self.statusMessage = "ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãªã—"
                    return
                }
                
                if httpResponse.statusCode == 200 {
                    // æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
                    self.parseWhisperResponse(data)
                } else {
                    // ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
                    if let errorMessage = String(data: data, encoding: .utf8) {
                        self.statusMessage = "API ã‚¨ãƒ©ãƒ¼ (\(httpResponse.statusCode)): \(errorMessage)"
                    } else {
                        self.statusMessage = "API ã‚¨ãƒ©ãƒ¼: HTTP \(httpResponse.statusCode)"
                    }
                }
            }
        }.resume()
    }
    
    // MARK: - Whisper ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
    private func parseWhisperResponse(_ data: Data) {
        do {
            if let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
               let text = json["text"] as? String {
                transcriptionResult = text
                statusMessage = "éŸ³å£°èªè­˜å®Œäº†ï¼"
                
                // å‡¦ç†æ™‚é–“æ¸¬å®šçµ‚äº†
                if let startTime = whisperStartTime {
                    let processingTime = Date().timeIntervalSince(startTime)
                    print("ğŸ™ï¸ Whisper APIå‡¦ç†å®Œäº†: \(String(format: "%.2f", processingTime))ç§’ - çµæœ: \"\(text)\"")
                }
                
            } else {
                statusMessage = "ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚¨ãƒ©ãƒ¼"
            }
        } catch {
            statusMessage = "JSONè§£æã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
        }
    }
    
    // MARK: - VADè¨­å®šèª¿æ•´ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    func adjustVADSettings(threshold: Float, silenceDuration: TimeInterval) {
        self.volumeThreshold = threshold
        self.silenceDuration = silenceDuration
        print("ğŸ”§ VADè¨­å®šå¤‰æ›´ - é–¾å€¤: \(threshold)dB, ç„¡éŸ³æ™‚é–“: \(silenceDuration)ç§’")
    }
    
    // MARK: - ç¾åœ¨ã®VADè¨­å®šç¢ºèª
    func printCurrentVADSettings() {
        print("ğŸ”§ ç¾åœ¨ã®VADè¨­å®šï¼ˆãƒãƒ©ãƒ³ã‚¹ç‰ˆï¼‰:")
        print("   volumeThreshold: \(volumeThreshold) dB")
        print("   silenceDuration: \(silenceDuration) ç§’")
        print("   monitoringInterval: \(monitoringInterval) ç§’")
    }
    
    // MARK: - å¤–éƒ¨çŠ¶æ…‹åˆ¶å¾¡
    func setThinkingState(_ thinking: Bool) {
        isThinking = thinking
        print("ğŸ§  AudioRecorder.isThinking = \(thinking)")
    }
    
    func pauseListeningForSpeech() {
        print("ğŸµ éŸ³å£°å†ç”Ÿã®ãŸã‚ãƒã‚¤ã‚¯ä¸€æ™‚åœæ­¢")
        monitoringTimer?.invalidate()
        monitoringRecorder?.stop()
        // isListeningã¯trueã®ã¾ã¾ï¼ˆä¸€æ™‚åœæ­¢çŠ¶æ…‹ï¼‰
    }

    func resumeListeningAfterSpeech() {
        print("ğŸµ éŸ³å£°å†ç”Ÿå®Œäº†ã€ãƒã‚¤ã‚¯å†é–‹")
        if isListening {
            startMonitoringLoop()
        }
    }
}
