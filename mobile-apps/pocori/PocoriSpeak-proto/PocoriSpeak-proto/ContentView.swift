import SwiftUI
import AVFoundation

// MARK: - ãƒ¡ã‚¤ãƒ³ãƒ“ãƒ¥ãƒ¼
struct ContentView: View {
    @StateObject private var speechManager = SpeechManager()
    @State private var inputText = "ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ãƒã‚³ãƒªã§ã™ã€‚ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€œ"
    
    var body: some View {
        VStack(spacing: 20) {
            // ãƒ˜ãƒƒãƒ€ãƒ¼
            VStack {
                Text("ğŸŒ¤ï¸ ãƒã‚³ãƒª")
                    .font(.largeTitle)
                    .fontWeight(.bold)
                
                Text("Speak Proto - éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ ")
                    .font(.subheadline)
                    .foregroundColor(.secondary)
            }
            .padding(.top)
            
            Spacer()
            
            // éŸ³å£°ç”Ÿæˆã‚¨ãƒªã‚¢
            VStack(spacing: 15) {
                // ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
                VStack(alignment: .leading) {
                    Text("ãƒã‚³ãƒªã«è©±ã—ã¦ã‚‚ã‚‰ã†å†…å®¹:")
                        .font(.headline)
                        .foregroundColor(.primary)
                    
                    TextEditor(text: $inputText)
                        .frame(minHeight: 100, maxHeight: 150)
                        .padding(8)
                        .background(Color.gray.opacity(0.1))
                        .cornerRadius(8)
                        .border(Color.gray.opacity(0.3), width: 1)
                }
                
                // éŸ³å£°ç”Ÿæˆãƒœã‚¿ãƒ³
                Button(action: {
                    speechManager.generateSpeech(text: inputText)
                }) {
                    HStack {
                        if speechManager.isGenerating {
                            ProgressView()
                                .progressViewStyle(CircularProgressViewStyle(tint: .white))
                                .scaleEffect(0.8)
                        } else {
                            Image(systemName: "waveform.circle.fill")
                                .font(.title2)
                        }
                        
                        Text(speechManager.isGenerating ? "éŸ³å£°ç”Ÿæˆä¸­..." : "ğŸŒ¤ï¸ ãƒã‚³ãƒªéŸ³å£°ã‚’ç”Ÿæˆ")
                            .fontWeight(.medium)
                    }
                    .foregroundColor(.white)
                    .padding()
                    .frame(maxWidth: .infinity)
                    .background(
                        speechManager.isGenerating || inputText.isEmpty ?
                        Color.gray : Color.blue
                    )
                    .cornerRadius(10)
                }
                .disabled(speechManager.isGenerating || inputText.isEmpty)
                
                // éŸ³å£°å†ç”Ÿã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
                if speechManager.hasAudio {
                    VStack(spacing: 10) {
                        Text("ğŸµ éŸ³å£°æº–å‚™å®Œäº†")
                            .font(.subheadline)
                            .foregroundColor(.green)
                        
                        HStack(spacing: 20) {
                            // å†ç”Ÿ/åœæ­¢ãƒœã‚¿ãƒ³
                            Button(action: {
                                if speechManager.isPlaying {
                                    speechManager.stopAudio()
                                } else {
                                    speechManager.playAudio()
                                }
                            }) {
                                HStack {
                                    Image(systemName: speechManager.isPlaying ? "stop.fill" : "play.fill")
                                        .font(.title2)
                                    Text(speechManager.isPlaying ? "åœæ­¢" : "å†ç”Ÿ")
                                        .fontWeight(.medium)
                                }
                                .foregroundColor(.white)
                                .padding(.horizontal, 20)
                                .padding(.vertical, 10)
                                .background(speechManager.isPlaying ? Color.red : Color.green)
                                .cornerRadius(8)
                            }
                            
                            // ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
                            Button(action: {
                                speechManager.resetAudio()
                            }) {
                                HStack {
                                    Image(systemName: "arrow.counterclockwise")
                                    Text("ãƒªã‚»ãƒƒãƒˆ")
                                }
                                .foregroundColor(.blue)
                                .padding(.horizontal, 15)
                                .padding(.vertical, 10)
                                .background(Color.blue.opacity(0.1))
                                .cornerRadius(8)
                            }
                        }
                    }
                    .padding()
                    .background(Color.green.opacity(0.1))
                    .cornerRadius(10)
                }
            }
            .padding(.horizontal)
            
            Spacer()
            
            // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
            if !speechManager.statusMessage.isEmpty {
                Text(speechManager.statusMessage)
                    .font(.caption)
                    .foregroundColor(.secondary)
                    .multilineTextAlignment(.center)
                    .padding(.horizontal)
            }
            
            // ãƒ—ãƒªã‚»ãƒƒãƒˆãƒ†ã‚­ã‚¹ãƒˆãƒœã‚¿ãƒ³
            VStack {
                Text("ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ:")
                    .font(.caption)
                    .foregroundColor(.secondary)
                
                ScrollView(.horizontal, showsIndicators: false) {
                    HStack {
                        ForEach(SpeechManager.sampleTexts, id: \.self) { sample in
                            Button(sample) {
                                inputText = sample
                            }
                            .font(.caption)
                            .padding(.horizontal, 12)
                            .padding(.vertical, 6)
                            .background(Color.blue.opacity(0.1))
                            .foregroundColor(.blue)
                            .cornerRadius(15)
                        }
                    }
                    .padding(.horizontal)
                }
            }
            .padding(.bottom)
        }
    }
}

// MARK: - éŸ³å£°ç®¡ç†ã‚¯ãƒ©ã‚¹
class SpeechManager: NSObject, ObservableObject {
    @Published var isGenerating = false
    @Published var isPlaying = false
    @Published var hasAudio = false
    @Published var statusMessage = ""
    // å‡¦ç†æ™‚é–“æ¸¬å®šç”¨
    private var speakStartTime: Date?
    
    private var audioPlayer: AVAudioPlayer?
    
    // ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
    static let sampleTexts = [
        "ã“ã‚“ã«ã¡ã¯ã€œãµã‚ãµã‚ã§ã™ã­",
        "ä»Šæ—¥ã¯ã„ã„ãŠå¤©æ°—ã§ã™ã­",
        "ã»ã‚ã»ã‚ã€œæ¥½ã—ãã†ã§ã™",
        "ãªã‚‹ã»ã©ã€œãã†ãªã‚“ã§ã™ã­",
        "ãµãƒ¼ã‚“ã€é¢ç™½ã„ã§ã™ã­"
    ]
    
    override init() {
        super.init()
        setupAudioSession()
    }
    
    private func setupAudioSession() {
        do {
            try AVAudioSession.sharedInstance().setCategory(.playback)
            try AVAudioSession.sharedInstance().setActive(true)
        } catch {
            statusMessage = "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
        }
    }
    
    // MARK: - OpenAI TTS APIå‘¼ã³å‡ºã—
    func generateSpeech(text: String) {
        guard !text.isEmpty else { return }
        
        isGenerating = true
        hasAudio = false
        statusMessage = "OpenAI TTS APIã§éŸ³å£°ã‚’ç”Ÿæˆä¸­..."
        
        callOpenAITTS(text: text)
    }
    
    private func callOpenAITTS(text: String) {
        // å‡¦ç†æ™‚é–“æ¸¬å®šé–‹å§‹
        speakStartTime = Date()
        print("ğŸ”Š Speak APIå‡¦ç†é–‹å§‹: \(Date())")
        
        let apiKey = "[OPENAI_API_KEY_PLACEHOLDER]"
        let url = URL(string: "https://api.openai.com/v1/audio/speech")!
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        
        let requestBody: [String: Any] = [
            "model": "tts-1",           // é«˜é€Ÿç‰ˆï¼ˆtts-1-hdã¯é«˜å“è³ªç‰ˆï¼‰
            "input": text,
            "voice": "nova",           // ä¸­æ€§çš„ãƒ»æ´»ç™ºãªå£°
            "response_format": "mp3",
            "speed": 1.0               // 1.0ãŒæ¨™æº–é€Ÿåº¦ï¼ˆ0.25ã€œ4.0ï¼‰
        ]
        
        do {
            request.httpBody = try JSONSerialization.data(withJSONObject: requestBody)
        } catch {
            DispatchQueue.main.async {
                self.statusMessage = "ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
                self.isGenerating = false
            }
            return
        }
        
        URLSession.shared.dataTask(with: request) { [weak self] data, response, error in
            DispatchQueue.main.async {
                guard let self = self else { return }
                
                if let error = error {
                    self.statusMessage = "é€šä¿¡ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
                    self.isGenerating = false
                    return
                }
                
                guard let data = data else {
                    self.statusMessage = "ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼"
                    self.isGenerating = false
                    return
                }
                
                // HTTPçŠ¶æ…‹ç¢ºèª
                if let httpResponse = response as? HTTPURLResponse {
                    if httpResponse.statusCode != 200 {
                        self.statusMessage = "API ã‚¨ãƒ©ãƒ¼: \(httpResponse.statusCode)"
                        self.isGenerating = false
                        return
                    }
                }
                
                // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’AVAudioPlayerã«è¨­å®š
                self.setupAudioPlayer(with: data)
            }
        }.resume()
    }
    
    private func setupAudioPlayer(with audioData: Data) {
        do {
            audioPlayer = try AVAudioPlayer(data: audioData)
            audioPlayer?.delegate = self
            audioPlayer?.prepareToPlay()
            
            hasAudio = true
            statusMessage = "éŸ³å£°ç”Ÿæˆå®Œäº†ï¼å†ç”Ÿãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„"
            isGenerating = false
            
            // å‡¦ç†æ™‚é–“æ¸¬å®šçµ‚äº†
            if let startTime = speakStartTime {
                let processingTime = Date().timeIntervalSince(startTime)
                print("ğŸ”Š Speak APIå‡¦ç†å®Œäº†: \(String(format: "%.2f", processingTime))ç§’ - éŸ³å£°ç”Ÿæˆå®Œäº†")
            }
            
        } catch {
            statusMessage = "éŸ³å£°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
            isGenerating = false
        }
    }
    
    // MARK: - éŸ³å£°å†ç”Ÿåˆ¶å¾¡
    func playAudio() {
        guard let player = audioPlayer else {
            statusMessage = "éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
            return
        }
        
        isPlaying = true
        statusMessage = "ğŸµ ãƒã‚³ãƒªãŒè©±ã—ã¦ã„ã¾ã™..."
        player.play()
    }
    
    func stopAudio() {
        audioPlayer?.stop()
        isPlaying = false
        statusMessage = "éŸ³å£°ã‚’åœæ­¢ã—ã¾ã—ãŸ"
        
        // åœæ­¢å¾Œã¯å…ˆé ­ã«æˆ»ã™
        audioPlayer?.currentTime = 0
    }
    
    func resetAudio() {
        audioPlayer?.stop()
        audioPlayer = nil
        hasAudio = false
        isPlaying = false
        statusMessage = ""
    }
}

// MARK: - AVAudioPlayerDelegate
extension SpeechManager: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        DispatchQueue.main.async {
            self.isPlaying = false
            self.statusMessage = flag ? "å†ç”Ÿå®Œäº†ï¼" : "å†ç”Ÿã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
        }
    }
    
    func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        DispatchQueue.main.async {
            self.isPlaying = false
            self.statusMessage = "éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: \(error?.localizedDescription ?? "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")"
        }
    }
}

// MARK: - ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}
